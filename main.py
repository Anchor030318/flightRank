#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
èˆªç­æ’åºDCN-v2æ¨¡å‹ - ä¸»å…¥å£æ–‡ä»¶

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„èˆªç­æ’åºè§£å†³æ–¹æ¡ˆï¼Œä½¿ç”¨DCN-v2ï¼ˆDeep Cross Network v2ï¼‰æ¨¡å‹ã€‚

ä½¿ç”¨æ–¹æ³•:
    python main.py --mode train    # è®­ç»ƒæ¨¡å¼
    python main.py --mode predict  # é¢„æµ‹æ¨¡å¼
    python main.py --mode all      # å®Œæ•´æµç¨‹ï¼ˆè®­ç»ƒ+é¢„æµ‹ï¼‰

ä½œè€…: Assistant
æ—¥æœŸ: 2024
"""

import argparse
import os
import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from train_pipeline import FlightRankingPipeline
from predict_pipeline import FlightPredictor
from submission_generator import SubmissionGenerator, SubmissionValidator

def check_files():
    """æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    required_files = {
        'data/train.parquet': 'è®­ç»ƒæ•°æ®',
        'data/test.parquet': 'æµ‹è¯•æ•°æ®'
    }
    
    missing_files = []
    for file_path, description in required_files.items():
        if not os.path.exists(file_path):
            missing_files.append(f"{file_path} ({description})")
    
    if missing_files:
        print("é”™è¯¯: ç¼ºå°‘ä»¥ä¸‹å¿…è¦æ–‡ä»¶:")
        for file in missing_files:
            print(f"  - {file}")
        print("\nè¯·ç¡®ä¿è®­ç»ƒå’Œæµ‹è¯•æ•°æ®æ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸‹ã€‚")
        return False
    
    return True

def train_model():
    """è®­ç»ƒæ¨¡å‹"""
    print("="*60)
    print("å¼€å§‹è®­ç»ƒDCN-v2èˆªç­æ’åºæ¨¡å‹")
    print("="*60)
    
    start_time = time.time()
    
    # é…ç½®å‚æ•°
    config = {
        'model': {
            'cross_layers': 3,              # äº¤å‰ç½‘ç»œå±‚æ•°
            'cross_low_rank': 32,           # ä½ç§©åˆ†è§£ç»´åº¦
            'deep_layers': [512, 256, 128], # æ·±åº¦ç½‘ç»œå±‚æ•°
            'dropout_rate': 0.3,            # Dropoutæ¯”ä¾‹
            'use_bn': True                  # æ˜¯å¦ä½¿ç”¨æ‰¹å½’ä¸€åŒ–
        },
        'training': {
            'batch_size': 256,              # æ‰¹æ¬¡å¤§å°
            'num_epochs': 50,               # è®­ç»ƒè½®æ•°
            'learning_rate': 0.001,         # å­¦ä¹ ç‡
            'optimizer': 'adam',            # ä¼˜åŒ–å™¨
            'weight_decay': 1e-5,           # æƒé‡è¡°å‡
            'margin': 1.0,                  # æ’åºæŸå¤±çš„è¾¹é™…
            'patience': 5,                  # å­¦ä¹ ç‡è°ƒåº¦è€å¿ƒ
            'early_stopping_patience': 10, # æ—©åœè€å¿ƒ
            'num_workers': 4                # æ•°æ®åŠ è½½è¿›ç¨‹æ•°
        }
    }
    
    try:
        # åˆ›å»ºè®­ç»ƒç®¡é“ï¼Œæ·»åŠ æ—¥å¿—æ–‡ä»¶
        pipeline = FlightRankingPipeline(config, log_file='train_pipeline.log')
        
        # åŠ è½½æ•°æ®
        pipeline.load_data('data/train.parquet', 'data/test.parquet')
        
        # è¿è¡Œå®Œæ•´è®­ç»ƒæµç¨‹
        pipeline.run_full_pipeline()
        
        training_time = time.time() - start_time
        print(f"\nâœ… è®­ç»ƒå®Œæˆ! è€—æ—¶: {training_time/60:.2f} åˆ†é’Ÿ")
        
        # ç»˜åˆ¶è®­ç»ƒå†å²ï¼ˆå¦‚æœå¯èƒ½ï¼‰
        try:
            pipeline.plot_training_history()
            print("ğŸ“Š è®­ç»ƒå†å²å›¾å·²ä¿å­˜ä¸º training_history.png")
        except ImportError:
            print("âš ï¸  matplotlibæœªå®‰è£…ï¼Œè·³è¿‡è®­ç»ƒå†å²ç»˜å›¾")
        
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

def predict_and_generate_submission():
    """é¢„æµ‹å¹¶ç”Ÿæˆæäº¤æ–‡ä»¶"""
    print("="*60)
    print("å¼€å§‹é¢„æµ‹å¹¶ç”Ÿæˆæäº¤æ–‡ä»¶")
    print("="*60)
    
    start_time = time.time()
    
    try:
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è®­ç»ƒå¥½çš„æ¨¡å‹
        pipeline_path = 'flight_ranking_pipeline'
        required_model_files = [
            f'{pipeline_path}_preprocessor.pkl',
            f'{pipeline_path}_feature_engineer.pkl',
            f'{pipeline_path}_scaler.pkl',
            f'{pipeline_path}_pipeline.pkl',
            'best_model.pth'
        ]
        
        missing_model_files = [f for f in required_model_files if not os.path.exists(f)]
        if missing_model_files:
            print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œè®­ç»ƒ:")
            for f in missing_model_files:
                print(f"  - {f}")
            return False
        
        # åˆ›å»ºé¢„æµ‹å™¨
        print("ğŸ“‚ åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")
        predictor = FlightPredictor(pipeline_path)
        
        # åŠ è½½æµ‹è¯•æ•°æ®
        print("ğŸ“Š åŠ è½½æµ‹è¯•æ•°æ®...")
        import pandas as pd
        test_data = pd.read_parquet('data/test.parquet')
        print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_data.shape}")
        
        # é¢„æµ‹
        print("ğŸ”® å¼€å§‹é¢„æµ‹...")
        if len(test_data) > 100000:
            # å¤§æ•°æ®é›†ä½¿ç”¨æ‰¹é‡é¢„æµ‹
            results = predictor.batch_predict(test_data, batch_size=50000)
        else:
            # å°æ•°æ®é›†ç›´æ¥é¢„æµ‹
            results = predictor.predict_ranking(test_data)
        
        # ä¿å­˜é¢„æµ‹ç»“æœ
        results.to_csv('prediction_results.csv', index=False)
        print("ğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: prediction_results.csv")
        
        # ç”Ÿæˆæäº¤æ–‡ä»¶
        print("ğŸ“ ç”Ÿæˆæäº¤æ–‡ä»¶...")
        generator = SubmissionGenerator()
        submission = generator.run_full_generation('prediction_results.csv', 'submission.csv')
        
        # éªŒè¯æäº¤æ–‡ä»¶
        print("ğŸ” éªŒè¯æäº¤æ–‡ä»¶...")
        validator = SubmissionValidator()
        
        format_ok = validator.validate_submission_format('submission.csv')
        cross_validation_ok = validator.validate_with_test_data('submission.csv', 'data/test.parquet')
        
        if format_ok and cross_validation_ok:
            prediction_time = time.time() - start_time
            print(f"\nâœ… é¢„æµ‹å’Œæäº¤æ–‡ä»¶ç”Ÿæˆå®Œæˆ! è€—æ—¶: {prediction_time/60:.2f} åˆ†é’Ÿ")
            print("ğŸ“„ æœ€ç»ˆæäº¤æ–‡ä»¶: submission.csv")
            return True
        else:
            print("âŒ æäº¤æ–‡ä»¶éªŒè¯å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='èˆªç­æ’åºDCN-v2æ¨¡å‹')
    parser.add_argument('--mode', choices=['train', 'predict', 'all'], 
                       default='all', help='è¿è¡Œæ¨¡å¼: train(è®­ç»ƒ), predict(é¢„æµ‹), all(å®Œæ•´æµç¨‹)')
    
    args = parser.parse_args()
    
    print("ğŸ›« èˆªç­æ’åºDCN-v2æ¨¡å‹")
    print("="*60)
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    if not check_files():
        sys.exit(1)
    
    success = True
    
    if args.mode in ['train', 'all']:
        success = train_model()
        if not success:
            sys.exit(1)
    
    if args.mode in ['predict', 'all']:
        success = predict_and_generate_submission()
        if not success:
            sys.exit(1)
    
    if success:
        print("\n" + "="*60)
        print("ğŸ‰ ä»»åŠ¡å®Œæˆ!")
        print("="*60)
        
        if args.mode in ['predict', 'all']:
            print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
            print("  - prediction_results.csv (è¯¦ç»†é¢„æµ‹ç»“æœ)")
            print("  - submission.csv (æœ€ç»ˆæäº¤æ–‡ä»¶)")
            print("  - submission_detailed.csv (è¯¦ç»†æäº¤ç»“æœ)")
            
        if args.mode in ['train', 'all']:
            print("ğŸ“ æ¨¡å‹æ–‡ä»¶:")
            print("  - best_model.pth (æœ€ä½³æ¨¡å‹)")
            print("  - flight_ranking_pipeline_*.pkl (é¢„å¤„ç†å™¨)")
            
        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print("  1. æ£€æŸ¥training_history.pngäº†è§£è®­ç»ƒè¿‡ç¨‹")
        print("  2. æŸ¥çœ‹submission.csvç¡®è®¤æäº¤æ ¼å¼")
        print("  3. å¯ä»¥è°ƒæ•´configå‚æ•°é‡æ–°è®­ç»ƒä»¥æé«˜æ€§èƒ½")

if __name__ == "__main__":
    main() 