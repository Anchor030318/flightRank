import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import warnings
warnings.filterwarnings('ignore')

class SubmissionGenerator:
    """æäº¤æ–‡ä»¶ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.submission_format = None
        self.validation_errors = []
    
    def load_predictions(self, predictions_path: str) -> pd.DataFrame:
        """
        åŠ è½½é¢„æµ‹ç»“æœ
        
        Args:
            predictions_path: é¢„æµ‹ç»“æœæ–‡ä»¶è·¯å¾„
            
        Returns:
            é¢„æµ‹ç»“æœDataFrame
        """
        print(f"åŠ è½½é¢„æµ‹ç»“æœ: {predictions_path}")
        
        if predictions_path.endswith('.csv'):
            df = pd.read_csv(predictions_path)
        elif predictions_path.endswith('.parquet'):
            df = pd.read_parquet(predictions_path)
        else:
            raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä½¿ç”¨CSVæˆ–Parquetæ ¼å¼")
        
        print(f"é¢„æµ‹ç»“æœå½¢çŠ¶: {df.shape}")
        return df
    
    def validate_predictions(self, df: pd.DataFrame) -> bool:
        """
        éªŒè¯é¢„æµ‹ç»“æœçš„æ­£ç¡®æ€§
        
        Args:
            df: é¢„æµ‹ç»“æœDataFrame
            
        Returns:
            æ˜¯å¦éªŒè¯é€šè¿‡
        """
        print("éªŒè¯é¢„æµ‹ç»“æœ...")
        self.validation_errors = []
        
        # æ£€æŸ¥å¿…è¦åˆ—
        required_columns = ['Id', 'ranker_id', 'predicted_score', 'rank']
        for col in required_columns:
            if col not in df.columns:
                self.validation_errors.append(f"ç¼ºå°‘å¿…è¦åˆ—: {col}")
        
        if self.validation_errors:
            return False
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        if not pd.api.types.is_numeric_dtype(df['Id']):
            self.validation_errors.append("Idåˆ—å¿…é¡»æ˜¯æ•°å€¼ç±»å‹")
        
        if not pd.api.types.is_numeric_dtype(df['predicted_score']):
            self.validation_errors.append("predicted_scoreåˆ—å¿…é¡»æ˜¯æ•°å€¼ç±»å‹")
        
        if not pd.api.types.is_integer_dtype(df['rank']):
            self.validation_errors.append("rankåˆ—å¿…é¡»æ˜¯æ•´æ•°ç±»å‹")
        
        # æ£€æŸ¥ç¼ºå¤±å€¼
        if df['Id'].isna().any():
            self.validation_errors.append("Idåˆ—å­˜åœ¨ç¼ºå¤±å€¼")
        
        if df['ranker_id'].isna().any():
            self.validation_errors.append("ranker_idåˆ—å­˜åœ¨ç¼ºå¤±å€¼")
        
        if df['rank'].isna().any():
            self.validation_errors.append("rankåˆ—å­˜åœ¨ç¼ºå¤±å€¼")
        
        # æ£€æŸ¥æ’åçš„æœ‰æ•ˆæ€§
        self._validate_rankings(df)
        
        if self.validation_errors:
            print("éªŒè¯å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯:")
            for error in self.validation_errors:
                print(f"  - {error}")
            return False
        
        print("éªŒè¯é€šè¿‡")
        return True
    
    def _validate_rankings(self, df: pd.DataFrame):
        """
        éªŒè¯æ’åçš„æ­£ç¡®æ€§
        
        Args:
            df: åŒ…å«æ’åçš„DataFrame
        """
        print("éªŒè¯æ’åæ­£ç¡®æ€§...")
        
        # æŒ‰ç»„æ£€æŸ¥æ’å
        for ranker_id, group in df.groupby('ranker_id'):
            ranks = sorted(group['rank'].values)
            group_size = len(group)
            expected_ranks = list(range(1, group_size + 1))
            
            # æ£€æŸ¥æ’åæ˜¯å¦ä»1å¼€å§‹ä¸”è¿ç»­
            if ranks != expected_ranks:
                self.validation_errors.append(
                    f"ç»„ {ranker_id} çš„æ’åä¸æ­£ç¡®: æœŸæœ› {expected_ranks}, å®é™… {ranks}"
                )
            
            # æ£€æŸ¥æ’åæ˜¯å¦å”¯ä¸€
            unique_ranks = len(set(group['rank'].values))
            if unique_ranks != group_size:
                self.validation_errors.append(
                    f"ç»„ {ranker_id} å­˜åœ¨é‡å¤æ’å: {group_size} ä¸ªè®°å½•ä½†åªæœ‰ {unique_ranks} ä¸ªå”¯ä¸€æ’å"
                )
    
    def fix_rankings(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ä¿®å¤æ’åé—®é¢˜
        
        Args:
            df: åŒ…å«æ’åçš„DataFrame
            
        Returns:
            ä¿®å¤åçš„DataFrame
        """
        print("ä¿®å¤æ’åé—®é¢˜...")
        
        def fix_group_ranking(group):
            """ä¿®å¤å•ä¸ªç»„çš„æ’å"""
            # æŒ‰é¢„æµ‹åˆ†æ•°é™åºæ’åº
            group = group.sort_values('predicted_score', ascending=False)
            
            # é‡æ–°åˆ†é…æ’å
            group['rank'] = range(1, len(group) + 1)
            
            return group
        
        # æŒ‰ç»„ä¿®å¤æ’å
        df_fixed = df.groupby('ranker_id').apply(fix_group_ranking).reset_index(drop=True)
        
        print("æ’åä¿®å¤å®Œæˆ")
        return df_fixed
    
    def create_submission_file(self, df: pd.DataFrame, output_path: str = 'submission.csv') -> pd.DataFrame:
        """
        åˆ›å»ºæäº¤æ–‡ä»¶
        
        Args:
            df: åŒ…å«æ’åçš„DataFrame
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            æäº¤æ ¼å¼çš„DataFrame
        """
        print("åˆ›å»ºæäº¤æ–‡ä»¶...")
        
        # åˆ›å»ºæäº¤æ ¼å¼
        submission = df[['Id', 'rank']].copy()
        
        # æŒ‰Idæ’åº
        submission = submission.sort_values('Id')
        
        # é‡ç½®ç´¢å¼•
        submission = submission.reset_index(drop=True)
        
        # ä¿å­˜æ–‡ä»¶
        submission.to_csv(output_path, index=False)
        
        print(f"æäº¤æ–‡ä»¶å·²ä¿å­˜: {output_path}")
        print(f"æäº¤æ–‡ä»¶å½¢çŠ¶: {submission.shape}")
        
        return submission
    
    def generate_submission_report(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        ç”Ÿæˆæäº¤æŠ¥å‘Š
        
        Args:
            df: åŒ…å«æ’åçš„DataFrame
            
        Returns:
            æäº¤æŠ¥å‘Šå­—å…¸
        """
        print("ç”Ÿæˆæäº¤æŠ¥å‘Š...")
        
        report = {
            'total_records': len(df),
            'total_groups': df['ranker_id'].nunique(),
            'avg_group_size': len(df) / df['ranker_id'].nunique(),
            'score_statistics': {
                'mean': df['predicted_score'].mean(),
                'std': df['predicted_score'].std(),
                'min': df['predicted_score'].min(),
                'max': df['predicted_score'].max(),
                'median': df['predicted_score'].median()
            },
            'rank_distribution': {},
            'group_size_distribution': {}
        }
        
        # æ’ååˆ†å¸ƒ
        rank_counts = df['rank'].value_counts().sort_index()
        report['rank_distribution'] = {
            'rank_1_count': rank_counts.get(1, 0),
            'rank_2_count': rank_counts.get(2, 0),
            'rank_3_count': rank_counts.get(3, 0),
            'max_rank': df['rank'].max(),
            'min_rank': df['rank'].min()
        }
        
        # ç»„å¤§å°åˆ†å¸ƒ
        group_sizes = df.groupby('ranker_id').size()
        report['group_size_distribution'] = {
            'min_group_size': group_sizes.min(),
            'max_group_size': group_sizes.max(),
            'avg_group_size': group_sizes.mean(),
            'group_size_counts': group_sizes.value_counts().to_dict()
        }
        
        return report
    
    def print_submission_report(self, report: Dict[str, Any]):
        """
        æ‰“å°æäº¤æŠ¥å‘Š
        
        Args:
            report: æäº¤æŠ¥å‘Šå­—å…¸
        """
        print("\n" + "="*50)
        print("æäº¤æ–‡ä»¶æŠ¥å‘Š")
        print("="*50)
        
        print(f"æ€»è®°å½•æ•°: {report['total_records']:,}")
        print(f"æ€»ç»„æ•°: {report['total_groups']:,}")
        print(f"å¹³å‡ç»„å¤§å°: {report['avg_group_size']:.2f}")
        
        print("\n--- åˆ†æ•°ç»Ÿè®¡ ---")
        stats = report['score_statistics']
        print(f"å¹³å‡åˆ†æ•°: {stats['mean']:.4f}")
        print(f"æ ‡å‡†å·®: {stats['std']:.4f}")
        print(f"æœ€å°å€¼: {stats['min']:.4f}")
        print(f"æœ€å¤§å€¼: {stats['max']:.4f}")
        print(f"ä¸­ä½æ•°: {stats['median']:.4f}")
        
        print("\n--- æ’ååˆ†å¸ƒ ---")
        rank_dist = report['rank_distribution']
        print(f"æ’å1çš„æ•°é‡: {rank_dist['rank_1_count']:,}")
        print(f"æ’å2çš„æ•°é‡: {rank_dist['rank_2_count']:,}")
        print(f"æ’å3çš„æ•°é‡: {rank_dist['rank_3_count']:,}")
        print(f"æœ€å¤§æ’å: {rank_dist['max_rank']}")
        print(f"æœ€å°æ’å: {rank_dist['min_rank']}")
        
        print("\n--- ç»„å¤§å°åˆ†å¸ƒ ---")
        group_dist = report['group_size_distribution']
        print(f"æœ€å°ç»„å¤§å°: {group_dist['min_group_size']}")
        print(f"æœ€å¤§ç»„å¤§å°: {group_dist['max_group_size']}")
        print(f"å¹³å‡ç»„å¤§å°: {group_dist['avg_group_size']:.2f}")
        
        print("\nç»„å¤§å°è®¡æ•°:")
        for size, count in sorted(group_dist['group_size_counts'].items()):
            print(f"  {size}ä¸ªèˆªç­çš„ç»„: {count:,} ä¸ª")
        
        print("="*50)
    
    def run_full_generation(self, predictions_path: str, output_path: str = 'submission.csv') -> pd.DataFrame:
        """
        è¿è¡Œå®Œæ•´çš„æäº¤æ–‡ä»¶ç”Ÿæˆæµç¨‹
        
        Args:
            predictions_path: é¢„æµ‹ç»“æœæ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            æäº¤æ ¼å¼çš„DataFrame
        """
        print("å¼€å§‹æäº¤æ–‡ä»¶ç”Ÿæˆæµç¨‹...")
        
        # åŠ è½½é¢„æµ‹ç»“æœ
        df = self.load_predictions(predictions_path)
        
        # éªŒè¯é¢„æµ‹ç»“æœ
        if not self.validate_predictions(df):
            print("é¢„æµ‹ç»“æœéªŒè¯å¤±è´¥ï¼Œå°è¯•ä¿®å¤...")
            df = self.fix_rankings(df)
            
            # å†æ¬¡éªŒè¯
            if not self.validate_predictions(df):
                raise ValueError("æ— æ³•ä¿®å¤é¢„æµ‹ç»“æœä¸­çš„é”™è¯¯")
        
        # åˆ›å»ºæäº¤æ–‡ä»¶
        submission = self.create_submission_file(df, output_path)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_submission_report(df)
        self.print_submission_report(report)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        detailed_output = output_path.replace('.csv', '_detailed.csv')
        df.to_csv(detailed_output, index=False)
        print(f"è¯¦ç»†ç»“æœå·²ä¿å­˜: {detailed_output}")
        
        print("æäº¤æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")
        return submission

class SubmissionValidator:
    """æäº¤æ–‡ä»¶éªŒè¯å™¨"""
    
    def __init__(self):
        pass
    
    def validate_submission_format(self, submission_path: str) -> bool:
        """
        éªŒè¯æäº¤æ–‡ä»¶æ ¼å¼
        
        Args:
            submission_path: æäº¤æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦éªŒè¯é€šè¿‡
        """
        print(f"éªŒè¯æäº¤æ–‡ä»¶æ ¼å¼: {submission_path}")
        
        try:
            # è¯»å–æäº¤æ–‡ä»¶
            df = pd.read_csv(submission_path)
            
            # æ£€æŸ¥åˆ—å
            if list(df.columns) != ['Id', 'rank']:
                print("é”™è¯¯: æäº¤æ–‡ä»¶å¿…é¡»åŒ…å«ä¸”ä»…åŒ…å« 'Id' å’Œ 'rank' ä¸¤åˆ—")
                return False
            
            # æ£€æŸ¥æ•°æ®ç±»å‹
            if not pd.api.types.is_integer_dtype(df['Id']):
                print("é”™è¯¯: Idåˆ—å¿…é¡»æ˜¯æ•´æ•°ç±»å‹")
                return False
            
            if not pd.api.types.is_integer_dtype(df['rank']):
                print("é”™è¯¯: rankåˆ—å¿…é¡»æ˜¯æ•´æ•°ç±»å‹")
                return False
            
            # æ£€æŸ¥ç¼ºå¤±å€¼
            if df.isna().any().any():
                print("é”™è¯¯: æäº¤æ–‡ä»¶ä¸èƒ½åŒ…å«ç¼ºå¤±å€¼")
                return False
            
            # æ£€æŸ¥æ’åèŒƒå›´
            if df['rank'].min() < 1:
                print("é”™è¯¯: æ’åå¿…é¡»ä»1å¼€å§‹")
                return False
            
            print("æäº¤æ–‡ä»¶æ ¼å¼éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"éªŒè¯è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return False
    
    def validate_with_test_data(self, submission_path: str, test_data_path: str) -> bool:
        """
        ä¸æµ‹è¯•æ•°æ®è¿›è¡Œäº¤å‰éªŒè¯
        
        Args:
            submission_path: æäº¤æ–‡ä»¶è·¯å¾„
            test_data_path: æµ‹è¯•æ•°æ®è·¯å¾„
            
        Returns:
            æ˜¯å¦éªŒè¯é€šè¿‡
        """
        print("ä¸æµ‹è¯•æ•°æ®è¿›è¡Œäº¤å‰éªŒè¯...")
        
        try:
            # è¯»å–æ–‡ä»¶
            submission = pd.read_csv(submission_path)
            test_data = pd.read_parquet(test_data_path)
            
            # æ£€æŸ¥Idæ˜¯å¦åŒ¹é…
            test_ids = set(test_data['Id'])
            submission_ids = set(submission['Id'])
            
            if test_ids != submission_ids:
                missing_ids = test_ids - submission_ids
                extra_ids = submission_ids - test_ids
                
                if missing_ids:
                    print(f"é”™è¯¯: ç¼ºå°‘ {len(missing_ids)} ä¸ªId")
                
                if extra_ids:
                    print(f"é”™è¯¯: å¤šå‡º {len(extra_ids)} ä¸ªId")
                
                return False
            
            # æ£€æŸ¥æ¯ä¸ªç»„çš„æ’å
            test_groups = test_data.groupby('ranker_id')['Id'].apply(set).to_dict()
            submission_dict = submission.set_index('Id')['rank'].to_dict()
            
            for ranker_id, group_ids in test_groups.items():
                group_ranks = [submission_dict[id_] for id_ in group_ids]
                expected_ranks = set(range(1, len(group_ids) + 1))
                actual_ranks = set(group_ranks)
                
                if expected_ranks != actual_ranks:
                    print(f"é”™è¯¯: ç»„ {ranker_id} çš„æ’åä¸æ­£ç¡®")
                    return False
            
            print("äº¤å‰éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            print(f"äº¤å‰éªŒè¯è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    print("å¯åŠ¨æäº¤æ–‡ä»¶ç”Ÿæˆå™¨...")
    
    # é…ç½®å‚æ•°
    predictions_path = 'prediction_results.csv'
    output_path = 'submission.csv'
    test_data_path = 'test.parquet'
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = SubmissionGenerator()
    
    # è¿è¡Œå®Œæ•´æµç¨‹
    try:
        submission = generator.run_full_generation(predictions_path, output_path)
        
        # éªŒè¯æäº¤æ–‡ä»¶
        validator = SubmissionValidator()
        
        # æ ¼å¼éªŒè¯
        if validator.validate_submission_format(output_path):
            print("âœ“ æäº¤æ–‡ä»¶æ ¼å¼éªŒè¯é€šè¿‡")
        else:
            print("âœ— æäº¤æ–‡ä»¶æ ¼å¼éªŒè¯å¤±è´¥")
            return
        
        # ä¸æµ‹è¯•æ•°æ®äº¤å‰éªŒè¯
        if validator.validate_with_test_data(output_path, test_data_path):
            print("âœ“ ä¸æµ‹è¯•æ•°æ®äº¤å‰éªŒè¯é€šè¿‡")
        else:
            print("âœ— ä¸æµ‹è¯•æ•°æ®äº¤å‰éªŒè¯å¤±è´¥")
            return
        
        print("\nğŸ‰ æäº¤æ–‡ä»¶ç”Ÿæˆå¹¶éªŒè¯æˆåŠŸï¼")
        print(f"æœ€ç»ˆæäº¤æ–‡ä»¶: {output_path}")
        
    except Exception as e:
        print(f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 